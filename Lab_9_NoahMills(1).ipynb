{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siujV5xu_QxV",
        "outputId": "8d480022-b1b1-44c3-ca79-d78bdaa9091a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN Accuracy: 1.0\n",
            "SVM Accuracy: 1.0\n",
            "NN Confusion Matrix: [[19  0  0]\n",
            " [ 0 13  0]\n",
            " [ 0  0 13]]\n",
            "SVM Confusion Matrix: [[19  0  0]\n",
            " [ 0 13  0]\n",
            " [ 0  0 13]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "x = iris.data\n",
        "y = iris.target\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Neural Network (MLP)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "x_train_scaled = scaler.transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10,3), max_iter=500, activation='relu', solver='adam', random_state=42)\n",
        "mlp.fit(x_train_scaled, y_train)\n",
        "nn_y_prediction = mlp.predict(x_test_scaled)\n",
        "nn_accuracy = accuracy_score(y_test, nn_y_prediction)\n",
        "print(f\"NN Accuracy: {nn_accuracy}\")\n",
        "\n",
        "# SVM Model\n",
        "model = SVC(kernel='linear')\n",
        "model.fit(x_train, y_train)\n",
        "svm_y_prediction = model.predict(x_test)\n",
        "svm_accuracy = accuracy_score(y_test, svm_y_prediction)\n",
        "print(f\"SVM Accuracy: {svm_accuracy}\")\n",
        "\n",
        "# Calculate/Plot confusion matrices\n",
        "nn_cm = confusion_matrix(y_test, nn_y_prediction)\n",
        "svm_cm = confusion_matrix(y_test, svm_y_prediction)\n",
        "\n",
        "print(f\"NN Confusion Matrix: {nn_cm}\")\n",
        "print(f\"SVM Confusion Matrix: {svm_cm}\")\n",
        "\n",
        "# fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# # NN Confusion Matrix\n",
        "# sns.heatmap(nn_cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=iris.target_names, yticklabels=iris.target_names, ax=axes[0])\n",
        "# axes[0].set_title(\"Neural Network Confusion Matrix\")\n",
        "# axes[0].set_xlabel(\"Predicted\")\n",
        "# axes[0].set_ylabel(\"Actual\")\n",
        "\n",
        "# # SVM Confusion Matrix\n",
        "# sns.heatmap(svm_cm, annot=True, fmt=\"d\", cmap=\"Oranges\", xticklabels=iris.target_names, yticklabels=iris.target_names, ax=axes[1])\n",
        "# axes[1].set_title(\"SVM Confusion Matrix\")\n",
        "# axes[1].set_xlabel(\"Predicted\")\n",
        "# axes[1].set_ylabel(\"Actual\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Write a brief summary discussing which model performed better on the Iris dataset and why this might be the case. Include neural network's configurations (hidden layers) details:*\n",
        "\n",
        "From what I can see, if the neural network is setup in a way that allows it to learn the dataset, they perform about the same. If you limit the number of neurons, hidden layers, or iterations too much the NN models accuracy will suffer. I tried to limit the number of neurons, hidden layers, and iterations while retaining an accuracy score of 1.0. These are the values I came to.\n",
        "\n",
        "**NN Details:** *mlp = MLPClassifier(hidden_layer_sizes=(10,3), max_iter=500, activation='relu', solver='adam', random_state=42)*\n",
        "\n",
        "The NN has 10 neurons with three hidden layers. It also has 500 iterations that it will attempt to do. Relu is the activation function used here and Adam is the optimization algorithm."
      ],
      "metadata": {
        "id": "y_Ec4aEdFbSH"
      }
    }
  ]
}